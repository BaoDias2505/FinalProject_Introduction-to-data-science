{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import isodate\n",
    "\n",
    "# Data visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", color_codes=True)\n",
    "\n",
    "# Google API\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "from IPython.display import JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = \"AIzaSyCJ39THFW-3CAzy4cbo4d8kts1ZuOeoyOM\" #vmphat24\n",
    "# api_key = \"AIzaSyACknQ39Hmkq_M41-MAXM-iIb2phykDEvY\" #pvminh\n",
    "# api_key = \"AIzaSyD1plVeU_boVWAezOXzkLal91NfaiPIf3M\" #vmphat21clc\n",
    "# api_key = \"AIzaSyA9N1-DIVh6DJQf430_bOvwRaJte0QOjl8\" #ngocquynhhh\n",
    "api_key = \"AIzaSyD7nKX_j2-7SjlOANbWcocik1M5BPxyv5I\" #tdtkiet.ytapi\n",
    "\n",
    "\n",
    "# https://www.streamweasels.com/tools/youtube-channel-id-and-user-id-convertor/\n",
    "channel_ids = [\n",
    "    # # ==================== pvminh ====================\n",
    "    # 'UCtYLUTtgS3k1Fg4y5tAhLbw', # StatQuest with Josh Starmer\n",
    "    # 'UCYO_jab_esuFRV4b17AJtAw', # 3Blue1Brown\n",
    "    # 'UCCezIgC97PvUuR4_gbFUs5g', # Corey Schafer\n",
    "    # 'UCfzlCWGWYyIQ0aLC5w48gBQ', # Sentdex\n",
    "    # 'UCh9nVJoWXmFb7sLApWGcLPQ', # codebasics \n",
    "    # 'UCNU_lfiiWBdtULKOw6X0Dig', # Krish Naik\n",
    "    # 'UCzL_0nIe8B4-7ShhVPfJkgw', # DatascienceDoJo\n",
    "    # 'UCLLw7jmFsvfIVaUFsLs8mlQ', # Luke Barousse \n",
    "    # 'UCiT9RITQ9PW6BhXK0y2jaeg', # Ken Jee\n",
    "    # 'UC7cs8q-gJRlGwj4A8OmCmXg', # Alex the Analyst\n",
    "    # 'UC2UXDak6o7rBm23k3Vv5dww', # Tina Huang\n",
    "    # 'UCxX9wt5FWQUAAz4UrysqK9A', # CS Dojo\n",
    "    # 'UCEBpSZhI1X8WaP-kY_2LLcg', # 365 Data Science\n",
    "    # 'UCV8e2g4IWQqK71bbzGDEI4Q', # Data Professor\n",
    "    # 'UCnVzApLJE2ljPZSeQylSEyg', # Data School\n",
    "    # 'UCBPRJjIWfyNG4X-CRbnv78A', # Abhishek Thakur\n",
    "    # 'UCUcpVoi5KkJmnE3bvEhHR0Q', # ritvikmath\n",
    "    # 'UCJQJAI7IjbLcpsjWdSzYz0Q', # Thu Vu data analytics\n",
    "    # 'UC6AVa0vSrCpuskzGDDKz_EQ', # zedstatistics\n",
    "    # 'UCnz-ZXXER4jOvuED5trXfEA', # techTFQ\n",
    "    # # -------------------- 1-20 --------------------\n",
    "\n",
    "    # # ==================== vmphat21clc ====================\n",
    "    # 'UCHXa4OpASJEwrHrLeIzw7Yg', # Nicholas Renotte\n",
    "    # 'UC5_6ZD6s8klmMu9TXEB_1IA', # CodeEmporium \n",
    "    # 'UCvZnwzmc3m1Eush-Or8Z6DA', # Shashank Kalanithi\n",
    "    # 'UCkYooZtwK_RJAd9SdL1jfeA', # The High ROI Data Scientist\n",
    "    # 'UCFrjdcImgcQVyFbK04MBEhA', # Brandon Foltz\n",
    "    # 'UCY8mzqqGwl5_bTpBY9qLMAA', # Andreas Kretz\n",
    "    # 'UC68KSmHePPePCjW4v57VPQg', # Python Programmer\n",
    "    # 'UCJublDh2UsiIKsAE1553miw', # Greg Hogg\n",
    "    # 'UCVhQ2NnY5Rskt6UjCUkJ_DA', # ArjanCodes\n",
    "    # 'UCh8IuVJvRdporrHi-I9H7Vw', # Unfold Data Science\n",
    "    # 'UCcQx1UnmorvmSEZef4X7-6g', # Jay Feng\n",
    "    # 'UCH6gDteHtH4hg3o2343iObA', # Analytics Vidhya\n",
    "    # 'UCR1-GEpyOPzT2AO4D_eifdw', # Jeff Heaton\n",
    "    # 'UCteRPiisgIoHtMgqHegpWAQ', # Sundas Khalid \n",
    "    # 'UC58v9cLitc8VaCjrcKyAbrw', # Machine Learning with Phil\n",
    "    # 'UCW8Ews7tdKKkBT6GdtQaXvQ', # StrataScratch\n",
    "    # 'UCMLtBahI5DMrt0NPvDSoIRQ', # Machine Learning Street Talk\n",
    "    # 'UCb0qAKEAwNC0FNatapc-yZg', # YUNIKARN\n",
    "    # 'UCeiiqmVK07qhY-wvg3IZiZQ', # David Robinson\n",
    "    # 'UCRqCK8izkO5xeVVtMKSHeRQ', # Data Nash\n",
    "    # # -------------------- 21-40 --------------------\n",
    "\n",
    "    # # ==================== ngocquynhhh ====================\n",
    "    # 'UCObs0kLIrDjX2LLSybqNaEA', # Great Learning\n",
    "    # 'UC79Gv3mYp6zKiSwYemEik9A', # DataCamp - Data Camp\n",
    "    # 'UCFp1vaKzpfvoGai0vE5VJ0w', # Guy in a Cube\n",
    "    # 'UC4JX40jDee_tINbkjycV4Sg', # Tech With Tim\n",
    "    # 'UCs10x-muRrTQMJ4Ya-fmIlw', # Snowflake Inc.\n",
    "    # 'UCGoxKRfTs0jQP52cfHCyyRQ', # MITCBMM\n",
    "    # 'UCJINtWke3-FMz2WuEltWDVQ', # Applied AI Course\n",
    "    # 'UCUzGQrN-lyyc0BWTYoJM_Sg', # What's AI by Louis Bouchard\n",
    "    # 'UCsBKTrp45lTfHa_p49I2AEQ', # Brandon Rohrer\n",
    "    # 'UCxladMszXan-jfgzyeIMyvw', # Rob Mulla\n",
    "    # 'UCCR6F6X28Kj00bgPCH9Ct_w', # Data Science with Sharan\n",
    "    # 'UCV0qA-eDDICsRR9rPcnG7tw', # Joma Tech\n",
    "    # 'UCtslD4DGH6PKyG_1gFAX7sg', # Alexander Amini\n",
    "    # 'UCn8ujwUInbJkBhffxqAPBVQ', # Dave Ebbelaar\n",
    "    # 'UC-YAxUbpa1hvRyfJBKFNcJA', # Leo Isikdogan\n",
    "    # 'UCwB7HrnRlOfasrbCJoiZ9Lg', # The Semicolon\n",
    "    # 'UCgBncpylJ1kiVaPyP-PZauQ', # Serrano.Academy\n",
    "    # 'UCVqU1Vy3HO4Ms-pbN0r2_kg', # Recall by Dataiku\n",
    "    # 'UCenqe6Cvfd47aHAOb9Qe8yA', # Damsel in Data\n",
    "    # 'UCNIkB2IeJ-6AmZv7bQ1oBYg', # Arxiv Insights\n",
    "    # # -------------------- 41-60 --------------------\n",
    "    \n",
    "    # # ==================== tdtkiet.ytapi ====================\n",
    "    # 'UCtY8JjMQpzYb5FFvUr2JnUw', # The Data Incubator\n",
    "    # 'UCX7Y2qWriXpqocG97SFW2OQ', # Jeremy Howard\n",
    "    # 'UC3q8O3Bh2Le8Rj1-Q-_UUbA', # Databricks\n",
    "    # 'UCn1USB9-5UqKJTSHd1JGcVw', # BEPEC by Kanth\n",
    "    # 'UChMU-aFKCoQyPOQzYph35YA', # The Engineer Guy 2.0\n",
    "    # 'UCmLGJ3VYBcfRaWbP6JLJcpA', # Seattle Data Guy\n",
    "    # 'UC9Wi1Ias8t4u1OosYnHhi0Q', # Hsuan-Tien Lin\n",
    "    # 'UCkzW5JSFwvKRjXABI-UTAkQ', # Aladdin Persson\n",
    "    # 'UC4UJ26WkceqONNF5S26OiVw', # deeplizard \n",
    "    # 'UCYoS2VT03weLA7uzvL2Vybw', # Alex Smola\n",
    "    # 'UCqd6TofKNjqagInm5Waeu7w', # Springboard\n",
    "    # 'UCqBbIn5Er4HevFg1wkeu-8A', # AI Planet\n",
    "    # 'UC-HLXw5cFC-7zqaXqTIlj-g', # Satyajit Pattnaik\n",
    "    # 'UC0g9jkx4MwsojJfBt1MnWew', # MYANMAR DATA SCIENCE\n",
    "    # 'UCZHmQk67mSJgfCCTn7xBfew', # Yannic Kilcher\n",
    "    # 'UCRjtBP-o5FbgRzX2BHQEFtQ', # Chai Time Data Science\n",
    "    # 'UCr8O8l5cCX85Oem1d18EezQ', # Daniel Bourke \n",
    "    # 'UC8ofcOdHNINiPrBA9D59Vaw', # Bhavesh Bhatt\n",
    "    # 'UC34rW-HtPJulxr5wp2Xa04w', # DigitalSreeni\n",
    "    # 'UCb1GdqUqArXMQ3RS86lqqOw', # iNeuron Intelligence\n",
    "    # # -------------------- 61-80 --------------------\n",
    "\n",
    "    # # ==================== frannievo.ytapi ====================\n",
    "    # 'UC3rY5HOgbBvGmq7RnDfwF7A', # Rishabh Mishra\n",
    "    # 'UCk5tiFqPvdjsl7yT4mmokmg', # Data Science Tutorials\n",
    "    # 'UCHGw1uT1XmqaRm-6W15-KlQ', # Data Science Basics\n",
    "    # 'UCAEgip72UcvYwjcqzcJ1I2g', # DataScience RoadMap\n",
    "    # 'UCkp0ctv0vCNfh7i7D9GnHhw', # The Data Science Channel\n",
    "    # 'UCyU1CDYl_NX8nsxCCkKfk3A', # FUN WITH DATA SCIENCE\n",
    "    # 'UCq6XkhO5SZ66N04IcPbqNcw', # Keith Galli \n",
    "    # 'UCR1bgsuXHmXWDXJlua1mK4Q', # Kanika Jindal\n",
    "    # 'UCw_LFe2pS8x3NyipGNJgeEA', # Learn with Lukas\n",
    "    # 'UCDybamfye5An6p-j1t2YMsg', # Data With Mo\n",
    "    # 'UCTRB_OkdfGEA80HyLYLL2UQ', # DataTrained\n",
    "    # 'UCBtOvx6gen_SlIjKtWdQZmw', # Data Science\n",
    "    # 'UC0GmdVKZhMM3Rmielp4oVAA', # Stefanovic \n",
    "    # 'UCcIXc5mJsHVYTZR1maL5l9w', # DeepLearningAI\n",
    "    # 'UCG04dVOTmbRYPY1wvshBVDQ', # Siddhardhan\n",
    "    # 'UCwgKmJM4ZJQRJ-U5NjvR2dg', # george hotz archive\n",
    "    # 'UCtatfZMf-8EkIwASXM4ts0A', # AssemblyAI\n",
    "    # 'UCCWi3hpnq_Pe03nGxuS7isg', # CampusX\n",
    "    # 'UCHNO_Y3DskuKiw9VTvo8AMw', # Trouble- Free\n",
    "    # 'UCmNXJXWONLNF6bdftGY0Otw', # Codanics\n",
    "    # # -------------------- 81-100 --------------------\n",
    "    \n",
    "    # # ==================== danieltran.ytapi ====================\n",
    "    # 'UCakdSIPsJqiOLqylgoYmwQg', # itversity\n",
    "    # 'UCsh8qhZ4Wm2IJDRsNr_5Z0A', # Smitha Kolan - Machine Learning Engineer\n",
    "    # 'UChIaUcs3tho6XhyU6K6KMrw', # Machine Learning TV\n",
    "    # 'UC7HYxRWmaNlJux-X7rNLZyw', # Tableau Tim\n",
    "    # 'UCL2ls5uXExB4p6_aZF2rUyg', # Anthony Smoak\n",
    "    # 'UCNJJIRGlnpS6yytn-9ADCOw', # Data Folkz\n",
    "    # 'UC4lrlpag0yO52XPhCmONXnw', # ViSIT\n",
    "    # 'UCRhhFunXogiEK3WiinHGTAQ', # MyStudy\n",
    "    # 'UCjrGJITO_pggWmjgPvUiHFA', # Arpan Gupta Data Scientist, IITian\n",
    "    # 'UCG6qpjVnBTTT8wLGBygANOQ', # MLOps.community\n",
    "    # 'UCBp3w4DCEC64FZr4k9ROxig', # Weights & Biases\n",
    "    # 'UCmKaoNn0OvxVAe7f_8sXYNQ', # Jovian\n",
    "    # 'UCKRgi-HJDEq0a3nhlG2nQvg', # Ricardo Calix\n",
    "    # 'UCa0RTSXWyZdh7IciV9r-3ow', # The Data Scientist Show - Daliana Liu\n",
    "    # 'UCu8WF59Scx9f3H1N_FgZUwQ', # Automata Learning Lab\n",
    "    # 'UCMGDKvc8-06jmxRrhYLr1_g', # Equitable Equations\n",
    "    # 'UCcfngi7_ASuo5jdWX0bNauQ', # How to Power BI \n",
    "    # 'UCQID78IY6EOojr5RUdD47MQ', # Data Driven NYC\n",
    "    # 'UCWPCd6tPtoLJYzQQ681pe5Q', # ggnot2\n",
    "    # 'UCeTSg29X4ZzoTvuynSVmrCA', # Quantitative Social Science Data Analysis\n",
    "    # # -------------------- 101-120 --------------------\n",
    "\n",
    "\n",
    "    'UC8r94_jZaoXv9qsgFwAdPQQ', # Mike Crowson\n",
    "    'UCu9fxVjTz5AJO7FR1upY02w', # Rajistics - data science, AI, and machine learning\n",
    "    'UCsOfIwAXj1fT6LDqEDEAb4g', # Goodly\n",
    "    'UCbXgNpp0jedKWcQiULLbDTA', # Patrick Loeber \n",
    "    'UCAezwIIm1SfsqdmbQI-65pA', # Data Council\n",
    "    'UCrY1Ro4UXwMib9Qug3eJNWA', # Kahan Data Solutions\n",
    "    'UCChmJrVa8kDg05JfCmxpLRw', # Darshil Parmar \n",
    "    'UCBGcs9XTL5U34oaSn_AsHqw', # E-Learning Bridge \n",
    "    'UCsKYXFnst0YUwAkR4m5J_fw', # TechLake\n",
    "    'UCwBs8TLOogwyGd0GxHCp-Dw', # AIEngineering\n",
    "    'UCpNUYWW0kiqyh0j5Qy3aU7w', # Mısra Turp\n",
    "    'UCP7jMXSY2xbc3KCAE0MHQ-A', # Google DeepMind\n",
    "    'UCpABUkWm8xMt5XmGcFb3EFg', # Nicolai Nielsen\n",
    "    'UCAlwrsgeJavG1vw9qSFOUmA', # Analytics India Magazine\n",
    "    'UCvjgXvBlbQiydffZU7m1_aw', # The Coding Train\n",
    "    'UCSHZKyawb77ixDdsGog4iWA', # Lex Fridman\n",
    "    'UCHB9VepY6kYvZjj0Bgxnpbw', # Connor Shorten\n",
    "    'UCEqgmyWChwvt6MFGGlmUQCQ', # Allen Institute for AI\n",
    "    'UCupQLyNchb9-2Z5lmUOIijw', # Alfredo Canziani\n",
    "    'UCCGoM_sk2UGIiaTdtG3tHBw', # Sreyobhilashi IT\n",
    "\n",
    "    # 'UCbfYPyITQ-7l4upoX8nvctg', # Two Minute Papers \n",
    "    # 'UCdngmbVKX1Tgre699-XLlUA', # TechWorld with Nana\n",
    "    # 'UCNbfqCkmHEyf1CVKjuhEW_A', # DataEng Uncomplicated\n",
    "    # 'UCQIMjZigvDj6tWFoMTsN5_g', # Penguin Analytics\n",
    "    # 'UC9LfrPNcIyHspci0t2W4T_w', # Data36 - Online Data Science Courses\n",
    "    # 'UC_lePY0Lm0E2-_IkYUWpI5A', # Dataquest\n",
    "    # 'UCY66vV1WTk_2lHg24cuJrtg', # The Data Digest\n",
    "    # 'UC5zx8Owijmv-bbhAK6Z9apg', # Artificial Intelligence - All in One\n",
    "    # 'UC7kjWIK1H8tfmFlzZO-wHMw', # The TWIML AI Podcast with Sam Charrington\n",
    "    # 'UCrBzGHKmGDcwLFnQGHJ3XYg', # giant_neural_network\n",
    "]\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(channel_ids) == len(set(channel_ids))\n",
    "len(channel_ids), len(set(channel_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_stats(youtube, channel_ids):\n",
    "    \"\"\"\n",
    "    Get channel statistics: title, subscriber count, view count, video count, upload playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    channels_ids: list of channel IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe containing the channel statistics for all channels in the provided list: title, subscriber count, view count, video count, upload playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "                part='snippet,contentDetails,statistics',\n",
    "                id=','.join(channel_ids))\n",
    "    response = request.execute() \n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(channelName = response['items'][i]['snippet']['title'],\n",
    "                    subscribers = response['items'][i]['statistics']['subscriberCount'],\n",
    "                    views = response['items'][i]['statistics']['viewCount'],\n",
    "                    totalVideos = response['items'][i]['statistics']['videoCount'],\n",
    "                    playlistId = response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])\n",
    "        all_data.append(data)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "def get_video_ids(youtube, playlist_id):\n",
    "    \"\"\"\n",
    "    Get list of video IDs of all videos in the given playlist\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    playlist_id: playlist ID of the channel\n",
    "    \n",
    "    Returns:\n",
    "    List of video IDs of all videos in the playlist\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    request = youtube.playlistItems().list(\n",
    "                part='contentDetails',\n",
    "                playlistId = playlist_id,\n",
    "                maxResults = 50)\n",
    "    response = request.execute()\n",
    "    \n",
    "    video_ids = []\n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "        \n",
    "    next_page_token = response.get('nextPageToken')\n",
    "    more_pages = True\n",
    "    \n",
    "    while more_pages:\n",
    "        if next_page_token is None:\n",
    "            more_pages = False\n",
    "        else:\n",
    "            request = youtube.playlistItems().list(\n",
    "                        part='contentDetails',\n",
    "                        playlistId = playlist_id,\n",
    "                        maxResults = 50,\n",
    "                        pageToken = next_page_token)\n",
    "            response = request.execute()\n",
    "    \n",
    "            for i in range(len(response['items'])):\n",
    "                video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "            \n",
    "            next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "    return video_ids\n",
    "\n",
    "def get_video_details(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get video statistics of all videos with given IDs\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with statistics of videos, i.e.:\n",
    "        'channelTitle', 'title', 'description', 'tags', 'publishedAt'\n",
    "        'viewCount', 'likeCount', 'favoriteCount', 'commentCount'\n",
    "        'duration', 'definition', 'caption'\n",
    "    \"\"\"\n",
    "        \n",
    "    all_video_info = []\n",
    "    \n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=','.join(video_ids[i:i+50])\n",
    "        )\n",
    "        response = request.execute() \n",
    "\n",
    "        for video in response['items']:\n",
    "            stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "                             'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "                             'contentDetails': ['duration', 'definition', 'caption']\n",
    "                            }\n",
    "            video_info = {}\n",
    "            video_info['video_id'] = video['id']\n",
    "\n",
    "            for k in stats_to_keep.keys():\n",
    "                for v in stats_to_keep[k]:\n",
    "                    try:\n",
    "                        video_info[v] = video[k][v]\n",
    "                    except:\n",
    "                        video_info[v] = None\n",
    "\n",
    "            all_video_info.append(video_info)\n",
    "            \n",
    "    return pd.DataFrame(all_video_info)\n",
    "\n",
    "def get_comments_in_videos(youtube, video_ids):\n",
    "    \"\"\"\n",
    "    Get top level comments as text from all videos with given IDs (only the first 10 comments due to quote limit of Youtube API)\n",
    "    Params:\n",
    "    \n",
    "    youtube: the build object from googleapiclient.discovery\n",
    "    video_ids: list of video IDs\n",
    "    \n",
    "    Returns:\n",
    "    Dataframe with video IDs and associated top level comment in text.\n",
    "    \n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    err_counter = 0 # To stop the loop when too many errors occur\n",
    "    for video_id in video_ids:\n",
    "        try:   \n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=video_id\n",
    "            )\n",
    "            response = request.execute()\n",
    "        \n",
    "            comments_in_video = [comment['snippet']['topLevelComment']['snippet']['textOriginal'] for comment in response['items'][0:10]]\n",
    "            comments_in_video_info = {'video_id': video_id, 'comments': comments_in_video}\n",
    "\n",
    "            all_comments.append(comments_in_video_info)\n",
    "            \n",
    "        except: \n",
    "            # When error occurs - most likely because comments are disabled on a video\n",
    "            print('Could not get comments for video ' + video_id)\n",
    "            err_counter += 1\n",
    "            if err_counter >= 10:\n",
    "                break\n",
    "        \n",
    "    return pd.DataFrame(all_comments)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_data = get_channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8873"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = channel_data.copy()\n",
    "s[\"totalVideos\"] = pd.to_numeric(s[\"totalVideos\"])\n",
    "s.sort_values(by=['totalVideos'], inplace=True, ascending=False)\n",
    "s[:]['totalVideos'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelName</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>views</th>\n",
       "      <th>totalVideos</th>\n",
       "      <th>playlistId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Analytics India Magazine</td>\n",
       "      <td>52200</td>\n",
       "      <td>4193416</td>\n",
       "      <td>1781</td>\n",
       "      <td>UUAlwrsgeJavG1vw9qSFOUmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Coding Train</td>\n",
       "      <td>1630000</td>\n",
       "      <td>119650670</td>\n",
       "      <td>1228</td>\n",
       "      <td>UUvjgXvBlbQiydffZU7m1_aw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The TWIML AI Podcast with Sam Charrington</td>\n",
       "      <td>16100</td>\n",
       "      <td>687552</td>\n",
       "      <td>1105</td>\n",
       "      <td>UU7kjWIK1H8tfmFlzZO-wHMw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Two Minute Papers</td>\n",
       "      <td>1500000</td>\n",
       "      <td>132415945</td>\n",
       "      <td>838</td>\n",
       "      <td>UUbfYPyITQ-7l4upoX8nvctg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Council</td>\n",
       "      <td>34400</td>\n",
       "      <td>3622474</td>\n",
       "      <td>824</td>\n",
       "      <td>UUAezwIIm1SfsqdmbQI-65pA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lex Fridman</td>\n",
       "      <td>3410000</td>\n",
       "      <td>542704196</td>\n",
       "      <td>784</td>\n",
       "      <td>UUSHZKyawb77ixDdsGog4iWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RADACAD</td>\n",
       "      <td>41900</td>\n",
       "      <td>5925800</td>\n",
       "      <td>507</td>\n",
       "      <td>UUsOfIwAXj1fT6LDqEDEAb4g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TechLake</td>\n",
       "      <td>38100</td>\n",
       "      <td>3767051</td>\n",
       "      <td>453</td>\n",
       "      <td>UUsKYXFnst0YUwAkR4m5J_fw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Artificial Intelligence - All in One</td>\n",
       "      <td>164000</td>\n",
       "      <td>4342522</td>\n",
       "      <td>413</td>\n",
       "      <td>UU5zx8Owijmv-bbhAK6Z9apg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mike Crowson</td>\n",
       "      <td>34700</td>\n",
       "      <td>7620512</td>\n",
       "      <td>405</td>\n",
       "      <td>UU8r94_jZaoXv9qsgFwAdPQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nicolai Nielsen</td>\n",
       "      <td>55400</td>\n",
       "      <td>3156608</td>\n",
       "      <td>398</td>\n",
       "      <td>UUpABUkWm8xMt5XmGcFb3EFg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E-Learning Bridge</td>\n",
       "      <td>163000</td>\n",
       "      <td>11115491</td>\n",
       "      <td>322</td>\n",
       "      <td>UUBGcs9XTL5U34oaSn_AsHqw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Connor Shorten</td>\n",
       "      <td>45700</td>\n",
       "      <td>2528241</td>\n",
       "      <td>291</td>\n",
       "      <td>UUHB9VepY6kYvZjj0Bgxnpbw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Allen Institute for AI</td>\n",
       "      <td>9990</td>\n",
       "      <td>535228</td>\n",
       "      <td>266</td>\n",
       "      <td>UUEqgmyWChwvt6MFGGlmUQCQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AIEngineering</td>\n",
       "      <td>72900</td>\n",
       "      <td>2914275</td>\n",
       "      <td>261</td>\n",
       "      <td>UUwBs8TLOogwyGd0GxHCp-Dw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rajistics - data science, AI, and machine lear...</td>\n",
       "      <td>2530</td>\n",
       "      <td>180806</td>\n",
       "      <td>249</td>\n",
       "      <td>UUu9fxVjTz5AJO7FR1upY02w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Patrick Loeber</td>\n",
       "      <td>253000</td>\n",
       "      <td>19580892</td>\n",
       "      <td>205</td>\n",
       "      <td>UUbXgNpp0jedKWcQiULLbDTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kahan Data Solutions</td>\n",
       "      <td>29900</td>\n",
       "      <td>3041106</td>\n",
       "      <td>193</td>\n",
       "      <td>UUrY1Ro4UXwMib9Qug3eJNWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Google DeepMind</td>\n",
       "      <td>463000</td>\n",
       "      <td>63690180</td>\n",
       "      <td>184</td>\n",
       "      <td>UUP7jMXSY2xbc3KCAE0MHQ-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mısra Turp</td>\n",
       "      <td>26200</td>\n",
       "      <td>1030065</td>\n",
       "      <td>140</td>\n",
       "      <td>UUpNUYWW0kiqyh0j5Qy3aU7w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Darshil Parmar</td>\n",
       "      <td>101000</td>\n",
       "      <td>4135527</td>\n",
       "      <td>137</td>\n",
       "      <td>UUChmJrVa8kDg05JfCmxpLRw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alfredo Canziani</td>\n",
       "      <td>37200</td>\n",
       "      <td>1469202</td>\n",
       "      <td>127</td>\n",
       "      <td>UUupQLyNchb9-2Z5lmUOIijw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sreyobhilashi IT</td>\n",
       "      <td>8360</td>\n",
       "      <td>647715</td>\n",
       "      <td>118</td>\n",
       "      <td>UUCGoM_sk2UGIiaTdtG3tHBw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TechWorld with Nana</td>\n",
       "      <td>954000</td>\n",
       "      <td>48984705</td>\n",
       "      <td>113</td>\n",
       "      <td>UUdngmbVKX1Tgre699-XLlUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DataEng Uncomplicated</td>\n",
       "      <td>14400</td>\n",
       "      <td>738499</td>\n",
       "      <td>98</td>\n",
       "      <td>UUNbfqCkmHEyf1CVKjuhEW_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Penguin Analytics</td>\n",
       "      <td>32400</td>\n",
       "      <td>3824758</td>\n",
       "      <td>81</td>\n",
       "      <td>UUQIMjZigvDj6tWFoMTsN5_g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data36 - Online Data Science Courses</td>\n",
       "      <td>4810</td>\n",
       "      <td>204069</td>\n",
       "      <td>69</td>\n",
       "      <td>UU9LfrPNcIyHspci0t2W4T_w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dataquest</td>\n",
       "      <td>43300</td>\n",
       "      <td>1423415</td>\n",
       "      <td>49</td>\n",
       "      <td>UU_lePY0Lm0E2-_IkYUWpI5A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Data Digest</td>\n",
       "      <td>3370</td>\n",
       "      <td>179569</td>\n",
       "      <td>36</td>\n",
       "      <td>UUY66vV1WTk_2lHg24cuJrtg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>giant_neural_network</td>\n",
       "      <td>36400</td>\n",
       "      <td>2088791</td>\n",
       "      <td>36</td>\n",
       "      <td>UUrBzGHKmGDcwLFnQGHJ3XYg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          channelName subscribers      views  \\\n",
       "14                           Analytics India Magazine       52200    4193416   \n",
       "23                                   The Coding Train     1630000  119650670   \n",
       "7           The TWIML AI Podcast with Sam Charrington       16100     687552   \n",
       "28                                  Two Minute Papers     1500000  132415945   \n",
       "11                                       Data Council       34400    3622474   \n",
       "22                                        Lex Fridman     3410000  542704196   \n",
       "4                                             RADACAD       41900    5925800   \n",
       "27                                           TechLake       38100    3767051   \n",
       "16               Artificial Intelligence - All in One      164000    4342522   \n",
       "3                                        Mike Crowson       34700    7620512   \n",
       "20                                    Nicolai Nielsen       55400    3156608   \n",
       "1                                   E-Learning Bridge      163000   11115491   \n",
       "10                                     Connor Shorten       45700    2528241   \n",
       "24                             Allen Institute for AI        9990     535228   \n",
       "8                                       AIEngineering       72900    2914275   \n",
       "15  Rajistics - data science, AI, and machine lear...        2530     180806   \n",
       "26                                     Patrick Loeber      253000   19580892   \n",
       "25                               Kahan Data Solutions       29900    3041106   \n",
       "13                                    Google DeepMind      463000   63690180   \n",
       "18                                         Mısra Turp       26200    1030065   \n",
       "21                                     Darshil Parmar      101000    4135527   \n",
       "6                                    Alfredo Canziani       37200    1469202   \n",
       "5                                    Sreyobhilashi IT        8360     647715   \n",
       "2                                 TechWorld with Nana      954000   48984705   \n",
       "19                              DataEng Uncomplicated       14400     738499   \n",
       "0                                   Penguin Analytics       32400    3824758   \n",
       "17               Data36 - Online Data Science Courses        4810     204069   \n",
       "9                                           Dataquest       43300    1423415   \n",
       "12                                    The Data Digest        3370     179569   \n",
       "29                               giant_neural_network       36400    2088791   \n",
       "\n",
       "    totalVideos                playlistId  \n",
       "14         1781  UUAlwrsgeJavG1vw9qSFOUmA  \n",
       "23         1228  UUvjgXvBlbQiydffZU7m1_aw  \n",
       "7          1105  UU7kjWIK1H8tfmFlzZO-wHMw  \n",
       "28          838  UUbfYPyITQ-7l4upoX8nvctg  \n",
       "11          824  UUAezwIIm1SfsqdmbQI-65pA  \n",
       "22          784  UUSHZKyawb77ixDdsGog4iWA  \n",
       "4           507  UUsOfIwAXj1fT6LDqEDEAb4g  \n",
       "27          453  UUsKYXFnst0YUwAkR4m5J_fw  \n",
       "16          413  UU5zx8Owijmv-bbhAK6Z9apg  \n",
       "3           405  UU8r94_jZaoXv9qsgFwAdPQQ  \n",
       "20          398  UUpABUkWm8xMt5XmGcFb3EFg  \n",
       "1           322  UUBGcs9XTL5U34oaSn_AsHqw  \n",
       "10          291  UUHB9VepY6kYvZjj0Bgxnpbw  \n",
       "24          266  UUEqgmyWChwvt6MFGGlmUQCQ  \n",
       "8           261  UUwBs8TLOogwyGd0GxHCp-Dw  \n",
       "15          249  UUu9fxVjTz5AJO7FR1upY02w  \n",
       "26          205  UUbXgNpp0jedKWcQiULLbDTA  \n",
       "25          193  UUrY1Ro4UXwMib9Qug3eJNWA  \n",
       "13          184  UUP7jMXSY2xbc3KCAE0MHQ-A  \n",
       "18          140  UUpNUYWW0kiqyh0j5Qy3aU7w  \n",
       "21          137  UUChmJrVa8kDg05JfCmxpLRw  \n",
       "6           127  UUupQLyNchb9-2Z5lmUOIijw  \n",
       "5           118  UUCGoM_sk2UGIiaTdtG3tHBw  \n",
       "2           113  UUdngmbVKX1Tgre699-XLlUA  \n",
       "19           98  UUNbfqCkmHEyf1CVKjuhEW_A  \n",
       "0            81  UUQIMjZigvDj6tWFoMTsN5_g  \n",
       "17           69  UU9LfrPNcIyHspci0t2W4T_w  \n",
       "9            49  UU_lePY0Lm0E2-_IkYUWpI5A  \n",
       "12           36  UUY66vV1WTk_2lHg24cuJrtg  \n",
       "29           36  UUrBzGHKmGDcwLFnQGHJ3XYg  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with video statistics and comments from all channels\n",
    "video_df = pd.DataFrame()\n",
    "comments_df = pd.DataFrame()\n",
    "\n",
    "for c in channel_data['channelName'].unique():\n",
    "    print(\"[LOG] Getting video information from channel: \" + c)\n",
    "    playlist_id = channel_data.loc[channel_data['channelName']== c, 'playlistId'].iloc[0]\n",
    "    video_ids = get_video_ids(youtube, playlist_id)\n",
    "    \n",
    "    # get video data\n",
    "    video_data = get_video_details(youtube, video_ids)\n",
    "    # get comment data\n",
    "    comments_data = get_comments_in_videos(youtube, video_ids)\n",
    "\n",
    "    # append video data together and comment data toghether\n",
    "    # append row of video data to video_df\n",
    "    video_df = pd.concat([video_df, video_data]) \n",
    "    comments_df = pd.concat([comments_df, comments_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nối dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "v1 = pd.read_csv(\"../data/raw/video_component/video_raw_data_1_20.csv\")\n",
    "v2 = pd.read_csv(\"../data/raw/video_component/video_raw_data_21_40.csv\")\n",
    "v3 = pd.read_csv(\"../data/raw/video_component/video_raw_data_41_60.csv\")\n",
    "v4 = pd.read_csv(\"../data/raw/video_component/video_raw_data_61_80.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.concat([v1, v2, v3, v4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30542, 13)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7285,)\n",
      "(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7285, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(v1[\"video_id\"].value_counts(dropna=False).shape)\n",
    "print(v1[\"channelTitle\"].value_counts(dropna=False).shape)\n",
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5789,)\n",
      "(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5789, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(v2[\"video_id\"].value_counts(dropna=False).shape)\n",
    "print(v2[\"channelTitle\"].value_counts(dropna=False).shape)\n",
    "v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_raw_video_df = pd.concat([v1, v2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13074"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.shape[0] + v2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13074,)\n",
      "(40,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13074, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(final_raw_video_df[\"video_id\"].value_counts(dropna=False).shape)\n",
    "print(final_raw_video_df[\"channelTitle\"].value_counts(dropna=False).shape)\n",
    "final_raw_video_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_raw_video_df.to_csv(\"../data/raw/video_raw_data.csv\", index=False, na_rep=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = pd.read_csv(\"../data/raw/comment_raw_data_1_20.csv\")\n",
    "c2 = pd.read_csv(\"../data/raw/comment_raw_data_21_40.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7269,)\n",
      "(6937,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7269, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(c1[\"video_id\"].value_counts(dropna=False).shape)\n",
    "print(c1[\"comments\"].value_counts(dropna=False).shape)\n",
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5762,)\n",
      "(4815,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5762, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(c2[\"video_id\"].value_counts(dropna=False).shape)\n",
    "print(c2[\"comments\"].value_counts(dropna=False).shape)\n",
    "c2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_raw_comment_df = pd.concat([c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13031,)\n",
      "(11750,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13031, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(final_raw_comment_df[\"video_id\"].value_counts(dropna=False).shape)\n",
    "print(final_raw_comment_df[\"comments\"].value_counts(dropna=False).shape)\n",
    "final_raw_comment_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_raw_comment_df.to_csv(\"../data/raw/comment_raw_data.csv\", index=False, na_rep=\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df = pd.read_csv(\"../data/raw/video_raw_data.csv\")\n",
    "comment_df = pd.read_csv(\"../data/raw/comment_raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13074 entries, 0 to 13073\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   video_id        13074 non-null  object \n",
      " 1   channelTitle    13074 non-null  object \n",
      " 2   title           13074 non-null  object \n",
      " 3   description     12658 non-null  object \n",
      " 4   tags            10903 non-null  object \n",
      " 5   publishedAt     13074 non-null  object \n",
      " 6   viewCount       13074 non-null  int64  \n",
      " 7   likeCount       13013 non-null  float64\n",
      " 8   favouriteCount  0 non-null      float64\n",
      " 9   commentCount    13068 non-null  float64\n",
      " 10  duration        13074 non-null  object \n",
      " 11  definition      13074 non-null  object \n",
      " 12  caption         13074 non-null  bool   \n",
      "dtypes: bool(1), float64(3), int64(1), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "video_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_df[\"channelTitle\"].value_counts(dropna=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13031 entries, 0 to 13030\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   video_id  13031 non-null  object\n",
      " 1   comments  13031 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 203.7+ KB\n"
     ]
    }
   ],
   "source": [
    "comment_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13031,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_df[\"video_id\"].value_counts(dropna=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_video_ids = comment_df[\"video_id\"].unique()\n",
    "video_video_ids   = video_df[\"video_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all video_id in comment_df are in video_df\n",
    "np.isin(comment_video_ids, video_video_ids).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(video_video_ids, comment_video_ids).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_1 = pd.read_csv(\"../data/raw/video_raw_data_1_20.csv\")\n",
    "v_2 = pd.read_csv(\"../data/raw/video_raw_data_1_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_1_2 = pd.concat([v_1, v_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7285,)\n",
      "(7285,)\n",
      "(7285,)\n"
     ]
    }
   ],
   "source": [
    "print(v_1[\"video_id\"].value_counts(dropna=False).shape)\n",
    "print(v_2[\"video_id\"].value_counts(dropna=False).shape)\n",
    "print(v_1_2[\"video_id\"].value_counts(dropna=False).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
